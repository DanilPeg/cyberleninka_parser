# Fast Parser - Парсер статей CyberLeninka

Парсер для скачивания научных статей с платформы CyberLeninka с фильтрацией по наличию аннотаций.

## Описание

`fast_parser.py` - это Python-скрипт для автоматического скачивания PDF-статей с сайта CyberLeninka. Парсер использует Playwright для эмуляции браузера и автоматически фильтрует статьи, оставляя только те, которые содержат аннотации. Парсинг происходит по категориям, требуется только url выбранной категории.

## Возможности

- **Автоматическое скачивание PDF** статей с CyberLeninka
- **Фильтрация по аннотациям** - скачиваются только статьи с аннотациями
- **CLI-интерфейс** с гибкими параметрами настройки
- **Режим стелс** для обхода антибот-защиты
- **Настраиваемые задержки** между запросами
- **Обработка постранично** с возможностью указания диапазона страниц
- **Автоматическое создание структуры папок**
- **Пропуск уже скачанных файлов**

## Требования

- Python 3.7+
- Playwright
- requests
- См. `requirements.txt` для полного списка зависимостей

## Установка

1. **Клонируйте репозиторий или скачайте файлы**
2. **Установите зависимости:**
   ```bash
   pip install -r requirements_fast_parser.txt
   ```
3. **Установите браузеры для Playwright:**
   ```bash
   playwright install chromium
   ```

## Использование

### Базовый синтаксис

```bash
python fast_parser.py --category-url "URL_РУБРИКИ" [ОПЦИИ]
```

### Обязательные параметры

- `--category-url, -u` - URL рубрики на CyberLeninka (обязательный)

### Опциональные параметры

- `--max-pages, -n` - Максимальное число страниц для обхода (по умолчанию: 10)
- `--start-page` - Номер страницы для начала скачивания (по умолчанию: 1)
- `--end-page` - Номер страницы для окончания скачивания (по умолчанию: max-pages)
- `--min-delay` - Минимальная задержка между запросами в секундах (по умолчанию: 0.5)
- `--max-delay` - Максимальная задержка между запросами в секундах (по умолчанию: 1.5)
- `--timeout` - Таймаут навигации Playwright в миллисекундах (по умолчанию: 20000)
- `--stealth` - Включить режим стелс для обхода антибот-защиты
- `--debug` - Включить отладочный режим

## Примеры использования

### 1. Скачать статьи с первой страницы рубрики

```bash
python fast_parser.py --category-url "https://cyberleninka.ru/article/c/mathematics"
```

### 2. Скачать статьи с первых 5 страниц

```bash
python fast_parser.py --category-url "https://cyberleninka.ru/article/c/mathematics" --max-pages 5
```

### 3. Скачать статьи с 3-й по 7-ю страницу

```bash
python fast_parser.py --category-url "https://cyberleninka.ru/article/c/mathematics" --start-page 3 --end-page 7
```

### 4. Использовать режим стелс с увеличенными задержками

```bash
python fast_parser.py --category-url "https://cyberleninka.ru/article/c/mathematics" --stealth --min-delay 2.0 --max-delay 5.0
```

### 5. Отладочный режим с подробным выводом

```bash
python fast_parser.py --category-url "https://cyberleninka.ru/article/c/mathematics" --debug --max-pages 2
```

## Структура выходных файлов

Парсер автоматически создает следующую структуру папок:

```
pages/
└── [Название_категории]/
    ├── Статья_1.pdf
    ├── Статья_2.pdf
    ├── Статья_3.pdf
    └── ...
```

## Рекомендации по использованию

### Для больших объемов (20+ страниц)
```bash
python fast_parser.py --category-url "URL" --max-pages 50 --stealth --min-delay 2.0 --max-delay 5.0
```

### Для обхода защиты
```bash
python fast_parser.py --category-url "URL" --stealth --min-delay 3.0 --max-delay 8.0
```


## Логирование

Парсер выводит подробную информацию о процессе:
- Количество найденных статей на каждой странице
- Статус скачивания каждой статьи
- Ошибки и предупреждения
- Общую статистику по завершении
